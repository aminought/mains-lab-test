{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set()\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv', index_col=0, parse_dates=['birthday', 'date'])\n",
    "test = pd.read_csv('test.csv', index_col=0, parse_dates=['birthday', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['service_lemm'] = train['service_lemm'].fillna('')\n",
    "test['service_lemm'] = test['service_lemm'].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "train['target'] = train['target'].apply(lambda x: literal_eval(x) if x is not np.nan else x)\n",
    "test['target'] = test['target'].apply(lambda x: literal_eval(x) if x is not np.nan else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sl = train[~train['target'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63646, 12)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sl.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "classes = np.unique(list(chain(*train_sl['target'].tolist())) + list(chain(*test['target'].tolist())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M',\n",
       "       'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y', 'Z'], dtype='<U1')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mb = MultiLabelBinarizer(classes=classes)\n",
    "y_train = mb.fit_transform(train_sl['target'])\n",
    "y_test = mb.transform(test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['num', 'birthday_year']\n",
    "cat_cols = ['service_class']\n",
    "text_cols = ['service_lemm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = num_cols + cat_cols + text_cols\n",
    "X_train = train_sl.loc[:, X_cols]\n",
    "X_test = test.loc[:, X_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_indices = np.argwhere(X_train.columns.isin(num_cols)).flatten()\n",
    "cat_indices = np.argwhere(X_train.columns.isin(cat_cols)).flatten()\n",
    "text_indices = np.argwhere(X_train.columns.isin(text_cols)).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>birthday_year</th>\n",
       "      <th>service_class</th>\n",
       "      <th>service_lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>129272</td>\n",
       "      <td>1</td>\n",
       "      <td>1968</td>\n",
       "      <td>4111</td>\n",
       "      <td>экг 12 ти отведение снятие расшифровка</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51064</td>\n",
       "      <td>1</td>\n",
       "      <td>1989</td>\n",
       "      <td>3100</td>\n",
       "      <td>общий клинический анализ кровь</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137191</td>\n",
       "      <td>1</td>\n",
       "      <td>1985</td>\n",
       "      <td>1810</td>\n",
       "      <td>забор материал рост флора чувствительность ант...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82671</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>3100</td>\n",
       "      <td>общеклинический исследование мочь микроскопия</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68484</td>\n",
       "      <td>1</td>\n",
       "      <td>1979</td>\n",
       "      <td>4500</td>\n",
       "      <td>эзофагоскопия лечебный диагностический т ч био...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        num  birthday_year  service_class  \\\n",
       "129272    1           1968           4111   \n",
       "51064     1           1989           3100   \n",
       "137191    1           1985           1810   \n",
       "82671     1           2017           3100   \n",
       "68484     1           1979           4500   \n",
       "\n",
       "                                             service_lemm  \n",
       "129272             экг 12 ти отведение снятие расшифровка  \n",
       "51064                      общий клинический анализ кровь  \n",
       "137191  забор материал рост флора чувствительность ант...  \n",
       "82671       общеклинический исследование мочь микроскопия  \n",
       "68484   эзофагоскопия лечебный диагностический т ч био...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(pl):\n",
    "    y_pred = pl.predict(X_test.values)\n",
    "    print(classification_report(y_test, y_pred, zero_division=0, target_names=mb.classes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "fu = FeatureUnion([\n",
    "    ('num', Pipeline([\n",
    "        ('select', FunctionTransformer(lambda X: X[:, num_indices], validate=False)),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])),\n",
    "    ('cat', Pipeline([\n",
    "        ('select', FunctionTransformer(lambda X: X[:, cat_indices], validate=False)),\n",
    "        ('onehot', OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore'))\n",
    "    ])),\n",
    "    ('text', Pipeline([\n",
    "        ('select', FunctionTransformer(lambda X: X[:, text_indices[0]], validate=False)),\n",
    "        ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "        ('toarray', FunctionTransformer(lambda X: X.toarray(), validate=False, accept_sparse=True))\n",
    "    ]))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = fu.fit_transform(X_train.values)\n",
    "X_test_transformed = fu.transform(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=20, random_state=42, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_train = kmeans.fit_predict(X_train_trasnformed)\n",
    "cluster_test = kmeans.predict(X_test_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['cluster'] = cluster_train\n",
    "X_test['cluster'] = cluster_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = ['num', 'birthday_year']\n",
    "cat_cols = ['service_class', 'cluster']\n",
    "text_cols = ['service_lemm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_indices = np.argwhere(X_train.columns.isin(num_cols)).flatten()\n",
    "cat_indices = np.argwhere(X_train.columns.isin(cat_cols)).flatten()\n",
    "text_indices = np.argwhere(X_train.columns.isin(text_cols)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('preprocess', FeatureUnion([\n",
    "        ('num', Pipeline([\n",
    "            ('select', FunctionTransformer(lambda X: X[:, num_indices], validate=False)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('cat', Pipeline([\n",
    "            ('select', FunctionTransformer(lambda X: X[:, cat_indices], validate=False)),\n",
    "            ('onehot', OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore'))\n",
    "        ])),\n",
    "        ('text', Pipeline([\n",
    "            ('select', FunctionTransformer(lambda X: X[:, text_indices[0]], validate=False)),\n",
    "            ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "            ('toarray', FunctionTransformer(lambda X: X.toarray(), validate=False, accept_sparse=True))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('pca', PCA(100)),\n",
    "    ('model', KNeighborsClassifier(n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.78 s, sys: 445 ms, total: 10.2 s\n",
      "Wall time: 2.57 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pl = pl.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       1.00      0.03      0.05       119\n",
      "           B       0.34      0.09      0.14       254\n",
      "           C       0.00      0.00      0.00        15\n",
      "           D       0.32      0.06      0.10       844\n",
      "           E       0.85      0.60      0.71      1737\n",
      "           F       1.00      0.10      0.18        30\n",
      "           G       0.51      0.21      0.30       811\n",
      "           H       0.86      0.80      0.83      1702\n",
      "           I       0.65      0.44      0.52      2391\n",
      "           J       0.69      0.57      0.62      3641\n",
      "           K       0.85      0.74      0.79      5363\n",
      "           L       0.58      0.30      0.40       758\n",
      "           M       0.79      0.73      0.76      4427\n",
      "           N       0.82      0.76      0.79      4486\n",
      "           O       0.00      0.00      0.00         2\n",
      "           P       0.00      0.00      0.00         1\n",
      "           Q       0.00      0.00      0.00        14\n",
      "           R       0.53      0.10      0.16       547\n",
      "           S       0.59      0.34      0.43       760\n",
      "           T       0.77      0.29      0.42       139\n",
      "           V       0.00      0.00      0.00         0\n",
      "           W       0.00      0.00      0.00        11\n",
      "           Y       0.00      0.00      0.00         2\n",
      "           Z       0.83      0.33      0.47       608\n",
      "\n",
      "   micro avg       0.78      0.60      0.68     28662\n",
      "   macro avg       0.50      0.27      0.32     28662\n",
      "weighted avg       0.75      0.60      0.65     28662\n",
      " samples avg       0.62      0.61      0.61     28662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(pl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('preprocess', FeatureUnion([\n",
    "        ('num', Pipeline([\n",
    "            ('select', FunctionTransformer(lambda X: X[:, num_indices], validate=False)),\n",
    "            ('scaler', StandardScaler())\n",
    "        ])),\n",
    "        ('cat', Pipeline([\n",
    "            ('select', FunctionTransformer(lambda X: X[:, cat_indices], validate=False)),\n",
    "            ('onehot', OneHotEncoder(sparse=False, categories='auto', handle_unknown='ignore'))\n",
    "        ])),\n",
    "        ('text', Pipeline([\n",
    "            ('select', FunctionTransformer(lambda X: X[:, text_indices[0]], validate=False)),\n",
    "            ('tfidf', TfidfVectorizer(min_df=50)),\n",
    "            ('toarray', FunctionTransformer(lambda X: X.toarray(), validate=False, accept_sparse=True))\n",
    "        ]))\n",
    "    ])),\n",
    "    ('pca', PCA(100)),\n",
    "    ('model', RandomForestClassifier(n_jobs=-1))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 54s, sys: 31.9 s, total: 7min 26s\n",
      "Wall time: 39.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pl = pl.fit(X_train.values, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.67      0.03      0.06       119\n",
      "           B       0.36      0.04      0.06       254\n",
      "           C       0.00      0.00      0.00        15\n",
      "           D       0.43      0.06      0.10       844\n",
      "           E       0.90      0.60      0.72      1737\n",
      "           F       0.00      0.00      0.00        30\n",
      "           G       0.55      0.15      0.24       811\n",
      "           H       0.90      0.80      0.85      1702\n",
      "           I       0.75      0.41      0.53      2391\n",
      "           J       0.77      0.56      0.65      3641\n",
      "           K       0.90      0.74      0.81      5363\n",
      "           L       0.68      0.34      0.45       758\n",
      "           M       0.84      0.74      0.79      4427\n",
      "           N       0.85      0.76      0.81      4486\n",
      "           O       0.00      0.00      0.00         2\n",
      "           P       0.00      0.00      0.00         1\n",
      "           Q       0.00      0.00      0.00        14\n",
      "           R       0.57      0.10      0.17       547\n",
      "           S       0.68      0.32      0.44       760\n",
      "           T       0.87      0.19      0.31       139\n",
      "           V       0.00      0.00      0.00         0\n",
      "           W       0.00      0.00      0.00        11\n",
      "           Y       0.00      0.00      0.00         2\n",
      "           Z       0.91      0.34      0.50       608\n",
      "\n",
      "   micro avg       0.84      0.60      0.70     28662\n",
      "   macro avg       0.48      0.26      0.31     28662\n",
      "weighted avg       0.80      0.60      0.67     28662\n",
      " samples avg       0.62      0.61      0.61     28662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_model(pl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
