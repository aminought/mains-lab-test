**Описание проблемы:**

В данных об оказанных медицинских услугах часто отсутствует информация о выставленном диагнозе. В то же время, эта информация очень важна для дальнейшего анализа и выявления завышений (фрода). Иногда диагноз не проставляется только по части услуг из кейса (case_id – идентификатор кейса), иногда не проставляется по всему кейсу.
 
**Что нужно сделать:**
- Предложить модель предсказания первой буквы кода диагноза (т.е. группу заболеваний) по оказанным услугам (см. поле service_class) и другой информации из кейса;
- Обучить модель на подмножестве строк из данного файла и протестировать её качество;
    
**Результат задания:**
- Ноутбук или файл .py с кодом для обработки данных и обучения модели + результаты предсказания на тестовой выборки + расчет метрик качества.


| Файл | Описание |
|------|----------|
| EDA.ipynb | Предварительный анализ данных |
| Preprocessing.ipynb | Предобработка данных |
| TSNE.ipynb | Визуализация данных с помощью t-SNE |
| Supervised.ipynb | Решение задачи с помощью обучения с учителем |
| Semi-supervised.ipynb | Решение задачи с помощью обучения с частичным привлечением учителя |
| Almost-supervised.ipynb | Решение задачи с помощью кластеризации и классификации |


В качестве признаков отдельно выделен год рождения, так как день и месяц не важны при постановке диагноза. Текст услуги лемматизирован при помощи MyStem и закодирован в tf-idf. Числовые признаки масштабируется, категориальные кодируются в one-hot матрицу, всё это происходит в пайплайне.

Целевая переменная (диагноз) извлекается при помощи регулярного выражения, далее происходит замена русских символов на соответствующие латинские.

Предлагается 3 способа решения задачи: supervised, semi-supervised и что-то вроде стэкинга с кластеризацией. 
1. В первом случае используется multi-label классификация, т.к. sklearn позволяет. Естественно, используются только те объекты, для которых проставлен диагноз. Не так много алгоритмов классификации в sklearn поддерживают multi-label классификацию. Был вариант использовать OneVsRestClassifier, но классов слишком много, это надолго. Еще есть библиотека scikit-multilearn, но решил, что будет достаточно типичных классификаторов из scikit-learn: KNN и RandomForest. RandomForest показал лучший результат, если смотреть по F1-мере.
1. Второй способ — каким-то образом использовать неразмеченную информацию. Это отдельная область задач, называется semi-supervised learning. В sklearn всего 2 таких алгоритма, и оба не поддерживаются multi-label классификацию. В качестве целевого класса выбираю первый попавшийся, сравнивать с первым подходом смысла нет, так как подсчет метрик производится по-разному, но по матрице ошибок видно, что хорошо предсказываются классы с наиболее частыми значениями.
1. Третий способ сам придумал: сначала кластеризую данные по всем признакам с помощью K-Means, затем добавляю номер кластера как новый признак, который потом преобразуется one-hot энкодером, и все это передается в алгоритм multi-label классификации. Прироста в качестве по сравнению с первым способом нет. Скорее всего, кластеры просто трудно нормально выделить, даже t-SNE с визуализацией особо не справился.

Проблемы и возможные решения:
- Нужна стратификация при разбиении на train и test, сложно выполнить при multi-label классификации.
- Подбор гиперпараметров.
- Возможно, где-то есть готовые и проверенные временем Python-реализации для semi-supervised multi-label classification, но я не нашел.